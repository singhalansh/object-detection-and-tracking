{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO('yolov10m.pt')\n",
    "\n",
    "# Load the class names\n",
    "class_list = model.names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 24.3ms\n",
      "Speed: 5.1ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.7ms\n",
      "Speed: 1.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.5ms\n",
      "Speed: 2.2ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.2ms\n",
      "Speed: 3.0ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.7ms\n",
      "Speed: 2.2ms preprocess, 17.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 3.1ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 3.3ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.7ms\n",
      "Speed: 2.3ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.2ms\n",
      "Speed: 2.2ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 3.0ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.0ms\n",
      "Speed: 2.6ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.2ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 2.1ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 2.3ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.7ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 1.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.3ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.4ms\n",
      "Speed: 2.3ms preprocess, 14.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.2ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.2ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.2ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 1.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.1ms\n",
      "Speed: 3.4ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.2ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.4ms\n",
      "Speed: 3.1ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.7ms\n",
      "Speed: 3.0ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.2ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 1.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21.3ms\n",
      "Speed: 2.0ms preprocess, 21.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.9ms\n",
      "Speed: 3.5ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.1ms\n",
      "Speed: 3.2ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.9ms\n",
      "Speed: 2.8ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.7ms\n",
      "Speed: 3.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.3ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 1.2ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.2ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 3.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.4ms\n",
      "Speed: 2.5ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 1.1ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.2ms\n",
      "Speed: 2.0ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 2.5ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 27.9ms\n",
      "Speed: 2.0ms preprocess, 27.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 1 cake, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 1 cake, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 1 cake, 18.2ms\n",
      "Speed: 1.0ms preprocess, 18.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 1 cake, 16.7ms\n",
      "Speed: 2.3ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 2 cakes, 14.8ms\n",
      "Speed: 3.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 2 cakes, 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 1 cake, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 1 cake, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 1 cake, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 21.5ms\n",
      "Speed: 3.0ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.2ms\n",
      "Speed: 3.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 ties, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 ties, 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 29.4ms\n",
      "Speed: 3.0ms preprocess, 29.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.6ms\n",
      "Speed: 1.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 20.7ms\n",
      "Speed: 3.1ms preprocess, 20.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 16.6ms\n",
      "Speed: 3.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 28.9ms\n",
      "Speed: 3.0ms preprocess, 28.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.5ms\n",
      "Speed: 3.4ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.0ms\n",
      "Speed: 3.3ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 ties, 24.5ms\n",
      "Speed: 4.0ms preprocess, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.3ms\n",
      "Speed: 3.1ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 28.7ms\n",
      "Speed: 3.1ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.1ms\n",
      "Speed: 3.2ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 30.4ms\n",
      "Speed: 3.0ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.2ms\n",
      "Speed: 3.2ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.4ms\n",
      "Speed: 3.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 25.1ms\n",
      "Speed: 4.0ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 29.5ms\n",
      "Speed: 2.6ms preprocess, 29.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.9ms\n",
      "Speed: 3.5ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.0ms\n",
      "Speed: 3.1ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.5ms\n",
      "Speed: 1.4ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 22.3ms\n",
      "Speed: 2.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 17.4ms\n",
      "Speed: 2.1ms preprocess, 17.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 31.8ms\n",
      "Speed: 3.0ms preprocess, 31.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 16.5ms\n",
      "Speed: 3.5ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 24.5ms\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 17.3ms\n",
      "Speed: 3.2ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 18.8ms\n",
      "Speed: 2.0ms preprocess, 18.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 tie, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 30.4ms\n",
      "Speed: 3.0ms preprocess, 30.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 17.3ms\n",
      "Speed: 3.3ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 29.8ms\n",
      "Speed: 2.1ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.7ms\n",
      "Speed: 1.5ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.3ms\n",
      "Speed: 3.1ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 30.1ms\n",
      "Speed: 3.0ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.0ms\n",
      "Speed: 2.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 dog, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 dog, 1 tie, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 dog, 1 tie, 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.6ms\n",
      "Speed: 3.1ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.0ms\n",
      "Speed: 1.5ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.7ms\n",
      "Speed: 3.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 28.8ms\n",
      "Speed: 3.0ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 dog, 1 tie, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 21.9ms\n",
      "Speed: 2.0ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 21.3ms\n",
      "Speed: 2.1ms preprocess, 21.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.5ms\n",
      "Speed: 2.5ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 17.8ms\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 28.8ms\n",
      "Speed: 3.0ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.7ms\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 28.8ms\n",
      "Speed: 3.2ms preprocess, 28.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 14.4ms\n",
      "Speed: 2.1ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 19.1ms\n",
      "Speed: 2.1ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 29.3ms\n",
      "Speed: 3.0ms preprocess, 29.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.7ms\n",
      "Speed: 3.0ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 29.4ms\n",
      "Speed: 2.2ms preprocess, 29.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 14.2ms\n",
      "Speed: 3.0ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 trucks, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 15.9ms\n",
      "Speed: 1.0ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 30.0ms\n",
      "Speed: 2.3ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 17.0ms\n",
      "Speed: 2.2ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 15.2ms\n",
      "Speed: 2.3ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 14.5ms\n",
      "Speed: 3.1ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.4ms\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.2ms\n",
      "Speed: 2.2ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.5ms\n",
      "Speed: 2.2ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 28.3ms\n",
      "Speed: 2.1ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 30.1ms\n",
      "Speed: 2.3ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 17.2ms\n",
      "Speed: 3.0ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 28.6ms\n",
      "Speed: 3.3ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 15.5ms\n",
      "Speed: 2.2ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 30.1ms\n",
      "Speed: 3.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 16.4ms\n",
      "Speed: 3.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 29.6ms\n",
      "Speed: 2.3ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 21.6ms\n",
      "Speed: 3.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 17.3ms\n",
      "Speed: 2.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.7ms\n",
      "Speed: 2.1ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 15.6ms\n",
      "Speed: 2.2ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 14.7ms\n",
      "Speed: 2.1ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.7ms\n",
      "Speed: 3.1ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 18.1ms\n",
      "Speed: 2.3ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 29.4ms\n",
      "Speed: 2.3ms preprocess, 29.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.0ms\n",
      "Speed: 2.1ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 14.8ms\n",
      "Speed: 3.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 18.1ms\n",
      "Speed: 2.4ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 15.5ms\n",
      "Speed: 1.5ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 3.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.2ms\n",
      "Speed: 3.0ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.6ms\n",
      "Speed: 3.0ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 3.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.0ms\n",
      "Speed: 2.6ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.4ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.7ms\n",
      "Speed: 2.1ms preprocess, 14.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.2ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.1ms\n",
      "Speed: 3.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.2ms\n",
      "Speed: 2.1ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 1.5ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.2ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.7ms\n",
      "Speed: 2.1ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 1.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 handbags, 25.3ms\n",
      "Speed: 3.2ms preprocess, 25.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 handbag, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 handbag, 29.9ms\n",
      "Speed: 3.0ms preprocess, 29.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 handbag, 29.8ms\n",
      "Speed: 2.1ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 handbag, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 handbag, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 handbag, 28.8ms\n",
      "Speed: 4.0ms preprocess, 28.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 26.5ms\n",
      "Speed: 3.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15.1ms\n",
      "Speed: 3.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 28.3ms\n",
      "Speed: 3.0ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 wine glass, 19.4ms\n",
      "Speed: 3.0ms preprocess, 19.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 19.3ms\n",
      "Speed: 2.0ms preprocess, 19.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 handbag, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 1 donut, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 17.4ms\n",
      "Speed: 3.3ms preprocess, 17.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 27.2ms\n",
      "Speed: 2.0ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 27.8ms\n",
      "Speed: 2.0ms preprocess, 27.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 29.3ms\n",
      "Speed: 3.0ms preprocess, 29.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 handbag, 1 cake, 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 handbag, 1 cake, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 handbag, 1 cake, 16.8ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 1 handbag, 1 cake, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 1 handbag, 1 cake, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 handbag, 1 cake, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 handbag, 1 cake, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 cake, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 cake, 21.2ms\n",
      "Speed: 1.0ms preprocess, 21.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 backpack, 1 cake, 27.4ms\n",
      "Speed: 2.4ms preprocess, 27.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 1 handbag, 1 cake, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 1 handbag, 1 cake, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 14.5ms\n",
      "Speed: 2.1ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.3ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 27.8ms\n",
      "Speed: 2.0ms preprocess, 27.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.6ms\n",
      "Speed: 2.2ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.5ms\n",
      "Speed: 2.7ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 17.4ms\n",
      "Speed: 4.0ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.5ms\n",
      "Speed: 2.2ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.5ms\n",
      "Speed: 3.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 1.2ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 3.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21.0ms\n",
      "Speed: 2.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 15.7ms\n",
      "Speed: 1.1ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.0ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.1ms\n",
      "Speed: 2.1ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.2ms\n",
      "Speed: 1.1ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 23.6ms\n",
      "Speed: 2.2ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cake, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cake, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cake, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cake, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cake, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cake, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cake, 27.7ms\n",
      "Speed: 1.0ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.6ms\n",
      "Speed: 2.4ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bird, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bird, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bird, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bird, 14.4ms\n",
      "Speed: 2.1ms preprocess, 14.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.2ms\n",
      "Speed: 3.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.5ms\n",
      "Speed: 2.4ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.6ms\n",
      "Speed: 1.5ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.5ms\n",
      "Speed: 2.1ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.3ms\n",
      "Speed: 3.1ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 17.5ms\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 3.4ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 14.5ms\n",
      "Speed: 2.3ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 16.0ms\n",
      "Speed: 3.3ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.1ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.4ms\n",
      "Speed: 3.0ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.5ms\n",
      "Speed: 3.7ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.5ms\n",
      "Speed: 3.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 donuts, 27.0ms\n",
      "Speed: 2.2ms preprocess, 27.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 donuts, 25.2ms\n",
      "Speed: 2.2ms preprocess, 25.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 donuts, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.8ms\n",
      "Speed: 3.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 2.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 26.6ms\n",
      "Speed: 3.3ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 16.9ms\n",
      "Speed: 2.2ms preprocess, 16.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.2ms\n",
      "Speed: 1.5ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 22.3ms\n",
      "Speed: 3.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 14.3ms\n",
      "Speed: 2.1ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 15.5ms\n",
      "Speed: 1.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 15.1ms\n",
      "Speed: 2.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 donut, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 1.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.2ms\n",
      "Speed: 2.0ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.6ms\n",
      "Speed: 2.1ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.8ms\n",
      "Speed: 2.0ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 3.0ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.7ms\n",
      "Speed: 3.3ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 1.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 3.0ms preprocess, 14.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.2ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.3ms\n",
      "Speed: 2.0ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 2.1ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.8ms\n",
      "Speed: 2.3ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.3ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.0ms\n",
      "Speed: 3.5ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.4ms\n",
      "Speed: 3.2ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 27.1ms\n",
      "Speed: 3.1ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.2ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.4ms\n",
      "Speed: 3.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 27.6ms\n",
      "Speed: 3.0ms preprocess, 27.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.7ms\n",
      "Speed: 2.1ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.7ms\n",
      "Speed: 2.5ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.0ms\n",
      "Speed: 2.4ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.7ms\n",
      "Speed: 4.5ms preprocess, 22.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.4ms\n",
      "Speed: 1.2ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18.3ms\n",
      "Speed: 2.0ms preprocess, 18.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.8ms\n",
      "Speed: 3.3ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 3.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18.3ms\n",
      "Speed: 2.4ms preprocess, 18.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 27.9ms\n",
      "Speed: 3.3ms preprocess, 27.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.4ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.5ms\n",
      "Speed: 2.4ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.7ms\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.1ms\n",
      "Speed: 2.2ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.4ms\n",
      "Speed: 2.2ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14.7ms\n",
      "Speed: 3.1ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.8ms\n",
      "Speed: 2.2ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.2ms\n",
      "Speed: 2.3ms preprocess, 21.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.6ms\n",
      "Speed: 2.2ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.3ms\n",
      "Speed: 1.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14.6ms\n",
      "Speed: 3.5ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14.7ms\n",
      "Speed: 2.5ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17.3ms\n",
      "Speed: 2.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.7ms\n",
      "Speed: 2.2ms preprocess, 20.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17.2ms\n",
      "Speed: 4.5ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.8ms\n",
      "Speed: 2.3ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17.8ms\n",
      "Speed: 2.0ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17.3ms\n",
      "Speed: 3.0ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.3ms\n",
      "Speed: 3.0ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.5ms\n",
      "Speed: 3.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17.5ms\n",
      "Speed: 3.0ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.1ms\n",
      "Speed: 3.2ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.3ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.3ms\n",
      "Speed: 3.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 3.2ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.6ms\n",
      "Speed: 2.6ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.7ms\n",
      "Speed: 2.5ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 2.3ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.4ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 3.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.4ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.2ms\n",
      "Speed: 3.1ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.9ms\n",
      "Speed: 2.1ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.4ms\n",
      "Speed: 2.6ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.2ms\n",
      "Speed: 3.1ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.5ms\n",
      "Speed: 3.1ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.7ms\n",
      "Speed: 3.1ms preprocess, 31.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.1ms\n",
      "Speed: 3.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 1.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 23.2ms\n",
      "Speed: 1.1ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.2ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21.3ms\n",
      "Speed: 3.0ms preprocess, 21.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.3ms\n",
      "Speed: 2.0ms preprocess, 30.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.2ms\n",
      "Speed: 2.0ms preprocess, 19.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.4ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.9ms\n",
      "Speed: 3.2ms preprocess, 25.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.5ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.7ms\n",
      "Speed: 2.1ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.0ms\n",
      "Speed: 2.6ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.6ms\n",
      "Speed: 2.1ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 3.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.7ms\n",
      "Speed: 3.4ms preprocess, 24.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 1.3ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 3.4ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 3.4ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 3.2ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.4ms\n",
      "Speed: 3.1ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 cup, 2 bowls, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 2 bowls, 15.1ms\n",
      "Speed: 2.1ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 2 bowls, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 cup, 2 bowls, 21.3ms\n",
      "Speed: 2.0ms preprocess, 21.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 cup, 2 bowls, 19.7ms\n",
      "Speed: 2.1ms preprocess, 19.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 2 bowls, 16.2ms\n",
      "Speed: 3.1ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 1 bowl, 15.8ms\n",
      "Speed: 3.1ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 16.1ms\n",
      "Speed: 2.6ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 16.7ms\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 16.0ms\n",
      "Speed: 3.4ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 2 bowls, 1 couch, 25.4ms\n",
      "Speed: 3.3ms preprocess, 25.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 1 bowl, 1 couch, 16.9ms\n",
      "Speed: 3.0ms preprocess, 16.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 1 bowl, 1 couch, 16.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 1 couch, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 1 bowl, 1 couch, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 cup, 1 bowl, 1 couch, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 cup, 1 bowl, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 cup, 1 bowl, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 17.6ms\n",
      "Speed: 2.0ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 22.2ms\n",
      "Speed: 2.1ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 33.5ms\n",
      "Speed: 3.3ms preprocess, 33.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 17.2ms\n",
      "Speed: 2.1ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 22.4ms\n",
      "Speed: 3.0ms preprocess, 22.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.0ms\n",
      "Speed: 3.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 15.2ms\n",
      "Speed: 3.5ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 couch, 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 couch, 31.7ms\n",
      "Speed: 2.1ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 17.1ms\n",
      "Speed: 3.0ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 17.1ms\n",
      "Speed: 3.0ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 19.7ms\n",
      "Speed: 2.3ms preprocess, 19.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 16.6ms\n",
      "Speed: 2.4ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 25.3ms\n",
      "Speed: 3.2ms preprocess, 25.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 21.8ms\n",
      "Speed: 3.5ms preprocess, 21.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bowl, 15.3ms\n",
      "Speed: 3.3ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 17.1ms\n",
      "Speed: 2.1ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 29.5ms\n",
      "Speed: 2.1ms preprocess, 29.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.6ms\n",
      "Speed: 2.5ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 21.5ms\n",
      "Speed: 2.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.5ms\n",
      "Speed: 4.0ms preprocess, 17.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.3ms\n",
      "Speed: 2.5ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 19.3ms\n",
      "Speed: 3.1ms preprocess, 19.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 29.4ms\n",
      "Speed: 3.2ms preprocess, 29.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.0ms\n",
      "Speed: 2.7ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.1ms\n",
      "Speed: 2.2ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 17.4ms\n",
      "Speed: 2.4ms preprocess, 17.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 19.2ms\n",
      "Speed: 3.0ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 1 couch, 19.8ms\n",
      "Speed: 2.0ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 2 couchs, 15.2ms\n",
      "Speed: 2.2ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 2 couchs, 15.6ms\n",
      "Speed: 2.2ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 2 couchs, 17.7ms\n",
      "Speed: 3.1ms preprocess, 17.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 2 couchs, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bowl, 2 couchs, 28.3ms\n",
      "Speed: 3.4ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.8ms\n",
      "Speed: 1.1ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 28.5ms\n",
      "Speed: 3.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 27.5ms\n",
      "Speed: 2.4ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 22.0ms\n",
      "Speed: 3.3ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.8ms\n",
      "Speed: 2.0ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.0ms\n",
      "Speed: 2.4ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.8ms\n",
      "Speed: 2.2ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.1ms\n",
      "Speed: 2.4ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 19.0ms\n",
      "Speed: 2.3ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.2ms\n",
      "Speed: 2.3ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.2ms\n",
      "Speed: 3.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.2ms\n",
      "Speed: 3.0ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.6ms\n",
      "Speed: 2.4ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 18.6ms\n",
      "Speed: 2.0ms preprocess, 18.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 29.9ms\n",
      "Speed: 3.0ms preprocess, 29.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.4ms\n",
      "Speed: 2.0ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.7ms\n",
      "Speed: 2.3ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.5ms\n",
      "Speed: 1.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 24.9ms\n",
      "Speed: 3.0ms preprocess, 24.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.8ms\n",
      "Speed: 3.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 20.2ms\n",
      "Speed: 3.1ms preprocess, 20.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.2ms\n",
      "Speed: 3.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 spoon, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 2 hot dogs, 2 donuts, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 2 hot dogs, 2 donuts, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 2 hot dogs, 2 donuts, 21.0ms\n",
      "Speed: 4.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 2 hot dogs, 2 donuts, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 hot dogs, 3 donuts, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 2 hot dogs, 4 donuts, 15.5ms\n",
      "Speed: 3.1ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 2 hot dogs, 3 donuts, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 sandwichs, 3 hot dogs, 2 donuts, 17.7ms\n",
      "Speed: 3.0ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 sandwichs, 2 hot dogs, 3 donuts, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 hot dogs, 3 donuts, 26.7ms\n",
      "Speed: 3.2ms preprocess, 26.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 hot dogs, 3 donuts, 20.7ms\n",
      "Speed: 3.0ms preprocess, 20.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 hot dogs, 3 donuts, 16.1ms\n",
      "Speed: 3.4ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 3 donuts, 16.3ms\n",
      "Speed: 3.3ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 sandwich, 3 donuts, 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 sandwich, 3 donuts, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 donuts, 25.6ms\n",
      "Speed: 3.6ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 donuts, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sandwich, 3 donuts, 16.6ms\n",
      "Speed: 2.1ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 2 donuts, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 2 hot dogs, 1 donut, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 2 hot dogs, 1 donut, 19.0ms\n",
      "Speed: 2.1ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 17.3ms\n",
      "Speed: 2.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 29.3ms\n",
      "Speed: 2.2ms preprocess, 29.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 14.5ms\n",
      "Speed: 2.4ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 hot dog, 2 donuts, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 hot dog, 2 donuts, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 2 donuts, 17.0ms\n",
      "Speed: 3.3ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 2 donuts, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 1 hot dog, 2 donuts, 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 1 hot dog, 2 donuts, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 donuts, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 hot dog, 2 donuts, 15.7ms\n",
      "Speed: 3.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 2 donuts, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 2 donuts, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 2 donuts, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 sandwich, 3 donuts, 17.1ms\n",
      "Speed: 3.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 2 donuts, 15.8ms\n",
      "Speed: 3.3ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 2 donuts, 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 2 donuts, 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 sandwichs, 2 donuts, 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 2 donuts, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 3 donuts, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 2 sandwichs, 3 donuts, 17.0ms\n",
      "Speed: 2.1ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 2 sandwichs, 1 hot dog, 3 donuts, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 2 sandwichs, 1 hot dog, 2 donuts, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 29.8ms\n",
      "Speed: 4.0ms preprocess, 29.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 15.4ms\n",
      "Speed: 2.7ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 tie, 1 sandwich, 1 hot dog, 2 donuts, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 2 donuts, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 2 donuts, 16.0ms\n",
      "Speed: 2.4ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 3 donuts, 21.0ms\n",
      "Speed: 2.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 donuts, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 donuts, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 2 hot dogs, 1 donut, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 2 hot dogs, 1 donut, 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 4 donuts, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 4 hot dogs, 1 donut, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 3 hot dogs, 1 donut, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 3 hot dogs, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 3 hot dogs, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 2 hot dogs, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 1 donut, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 2 donuts, 30.2ms\n",
      "Speed: 3.3ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 2 hot dogs, 1 donut, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 2 hot dogs, 1 donut, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 19.2ms\n",
      "Speed: 3.0ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 14.4ms\n",
      "Speed: 2.3ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 hot dog, 15.5ms\n",
      "Speed: 3.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 1 hot dog, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 1 hot dog, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 1 hot dog, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.3ms\n",
      "Speed: 2.4ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 15.7ms\n",
      "Speed: 3.1ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 22.0ms\n",
      "Speed: 3.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 23.1ms\n",
      "Speed: 2.0ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 donut, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 17.5ms\n",
      "Speed: 3.0ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 15.0ms\n",
      "Speed: 2.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 16.0ms\n",
      "Speed: 3.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 1 donut, 15.7ms\n",
      "Speed: 3.6ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 2 donuts, 16.0ms\n",
      "Speed: 3.3ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 donut, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 sandwichs, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 sandwichs, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 sandwichs, 14.2ms\n",
      "Speed: 2.2ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 sandwichs, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 sandwichs, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 sandwichs, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 3 sandwichs, 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 14.5ms\n",
      "Speed: 2.4ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 14.1ms\n",
      "Speed: 3.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.1ms\n",
      "Speed: 2.3ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 1 sandwich, 16.2ms\n",
      "Speed: 3.5ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 22.5ms\n",
      "Speed: 3.4ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 16.8ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 28.4ms\n",
      "Speed: 3.0ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 17.3ms\n",
      "Speed: 2.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 ties, 2 sandwichs, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.4ms\n",
      "Speed: 3.1ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 21.8ms\n",
      "Speed: 3.0ms preprocess, 21.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.5ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.7ms\n",
      "Speed: 3.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 3.1ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.1ms\n",
      "Speed: 2.6ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 18.1ms\n",
      "Speed: 4.0ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.4ms\n",
      "Speed: 3.0ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 1.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 1.2ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.6ms\n",
      "Speed: 3.5ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 3.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.9ms\n",
      "Speed: 2.0ms preprocess, 17.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 18.8ms\n",
      "Speed: 2.0ms preprocess, 18.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 2.4ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.6ms\n",
      "Speed: 2.0ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.4ms\n",
      "Speed: 3.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 3.1ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 27.6ms\n",
      "Speed: 2.7ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.8ms\n",
      "Speed: 3.1ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.3ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.1ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.8ms\n",
      "Speed: 2.4ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 19.6ms\n",
      "Speed: 2.0ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 3.1ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.3ms\n",
      "Speed: 2.0ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 27.7ms\n",
      "Speed: 2.1ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.2ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.7ms\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.1ms\n",
      "Speed: 2.8ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.0ms\n",
      "Speed: 2.2ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.5ms\n",
      "Speed: 3.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 1.1ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.8ms\n",
      "Speed: 2.4ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 29.1ms\n",
      "Speed: 3.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.5ms\n",
      "Speed: 2.5ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 19.3ms\n",
      "Speed: 3.4ms preprocess, 19.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 15.4ms\n",
      "Speed: 2.2ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 16.9ms\n",
      "Speed: 1.1ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 28.3ms\n",
      "Speed: 3.0ms preprocess, 28.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.8ms\n",
      "Speed: 2.3ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.4ms\n",
      "Speed: 3.0ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 20.4ms\n",
      "Speed: 2.0ms preprocess, 20.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.3ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.8ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.7ms\n",
      "Speed: 3.2ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.2ms\n",
      "Speed: 3.2ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.6ms\n",
      "Speed: 2.2ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 27.9ms\n",
      "Speed: 2.0ms preprocess, 27.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 29.3ms\n",
      "Speed: 2.5ms preprocess, 29.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.7ms\n",
      "Speed: 3.0ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.0ms\n",
      "Speed: 2.1ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.3ms\n",
      "Speed: 3.0ms preprocess, 28.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 20.3ms\n",
      "Speed: 2.0ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 4.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.8ms\n",
      "Speed: 2.3ms preprocess, 14.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 22.1ms\n",
      "Speed: 3.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.1ms\n",
      "Speed: 3.2ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.6ms\n",
      "Speed: 2.0ms preprocess, 18.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 1.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.4ms preprocess, 28.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 30.1ms\n",
      "Speed: 3.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.0ms\n",
      "Speed: 2.3ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.2ms\n",
      "Speed: 1.1ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 3.2ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.8ms\n",
      "Speed: 2.0ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 20.2ms\n",
      "Speed: 3.0ms preprocess, 20.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.9ms\n",
      "Speed: 3.0ms preprocess, 17.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 2.3ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.0ms\n",
      "Speed: 3.1ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.7ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.2ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.3ms\n",
      "Speed: 2.5ms preprocess, 18.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.2ms\n",
      "Speed: 3.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.4ms\n",
      "Speed: 3.0ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 1.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.1ms\n",
      "Speed: 3.0ms preprocess, 28.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.4ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.1ms\n",
      "Speed: 2.1ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.5ms\n",
      "Speed: 3.1ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 2.1ms preprocess, 27.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.8ms\n",
      "Speed: 2.1ms preprocess, 24.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.3ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.5ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.1ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.2ms\n",
      "Speed: 2.4ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.0ms\n",
      "Speed: 2.5ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.2ms\n",
      "Speed: 3.3ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.0ms\n",
      "Speed: 2.1ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.0ms preprocess, 27.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.1ms\n",
      "Speed: 3.1ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.7ms\n",
      "Speed: 2.0ms preprocess, 17.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.6ms\n",
      "Speed: 3.3ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.8ms\n",
      "Speed: 3.5ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.8ms\n",
      "Speed: 3.2ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.1ms\n",
      "Speed: 1.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.1ms\n",
      "Speed: 1.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.5ms\n",
      "Speed: 2.5ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 3.1ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.1ms\n",
      "Speed: 2.5ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 3.1ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.8ms\n",
      "Speed: 1.1ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.3ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.4ms\n",
      "Speed: 3.0ms preprocess, 16.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.3ms\n",
      "Speed: 2.5ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 30.8ms\n",
      "Speed: 3.0ms preprocess, 30.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 15.0ms\n",
      "Speed: 2.4ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 17.4ms\n",
      "Speed: 3.3ms preprocess, 17.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.3ms\n",
      "Speed: 3.0ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.5ms\n",
      "Speed: 2.2ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.6ms\n",
      "Speed: 2.4ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 1.1ms preprocess, 15.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.0ms\n",
      "Speed: 1.1ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.5ms\n",
      "Speed: 2.6ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.2ms\n",
      "Speed: 3.0ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.3ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.5ms\n",
      "Speed: 2.3ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.7ms\n",
      "Speed: 2.5ms preprocess, 18.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 2.1ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 3.2ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.2ms\n",
      "Speed: 1.3ms preprocess, 19.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.0ms\n",
      "Speed: 2.1ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.1ms\n",
      "Speed: 2.3ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 1.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.7ms\n",
      "Speed: 2.4ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.0ms\n",
      "Speed: 4.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.0ms\n",
      "Speed: 4.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.5ms\n",
      "Speed: 2.1ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.8ms\n",
      "Speed: 2.5ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 2.5ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.8ms\n",
      "Speed: 2.2ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Tracking data has been saved to 'tracking_data_output.json'\n",
      "Output video saved as 'output_video.mp4'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO('yolov10m.pt')\n",
    "\n",
    "# Load the class names\n",
    "class_list = model.names\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('testvideo.mp4')\n",
    "\n",
    "# Initialize video writer for saving the output video\n",
    "output_video_path = 'output_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for the output video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Get the video's FPS\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Initialize variables for tracking\n",
    "tracking_timestamps = {}\n",
    "disappearance_counts = {}\n",
    "debounce_limit = 10  # Frames for debouncing\n",
    "max_disappearance_time = debounce_limit / fps  # Max time in seconds to debounce\n",
    "frame_buffer = {}  # To hold the last known frame for each object\n",
    "\n",
    "# New JSON structure\n",
    "tracking_data_json = []\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_number += 1\n",
    "    timestamp = frame_number / fps  # Calculate the timestamp for each frame\n",
    "\n",
    "    # Perform model prediction on the current frame\n",
    "    results = model.predict(frame)\n",
    "\n",
    "    # Check if the results contain any detection data\n",
    "    if not results or results[0].boxes is None:\n",
    "        continue  # Skip if there are no detection results\n",
    "\n",
    "    # Extract the bounding box data\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()  # Convert to numpy array\n",
    "    px = pd.DataFrame(a)\n",
    "\n",
    "    # List to keep track of IDs detected in this frame\n",
    "    detected_ids = []\n",
    "\n",
    "    # Iterate over each detection in the frame\n",
    "    for index, row in px.iterrows():\n",
    "        x1, y1, x2, y2, conf, d = row\n",
    "\n",
    "        # Only consider detections with confidence > 0.5\n",
    "        if conf > 0.5 and int(d) < len(class_list):\n",
    "            c = class_list[int(d)]  # Get the class name\n",
    "            id = int(index)  # Assign a unique ID for the object\n",
    "\n",
    "            detected_ids.append(id)\n",
    "\n",
    "            # Check if the object is being detected after disappearing for a while\n",
    "            if id not in tracking_timestamps:\n",
    "                # If this is the first detection of this object or it's been missing, reset start_time\n",
    "                tracking_timestamps[id] = {\n",
    "                    \"class\": c,\n",
    "                    \"start_time\": timestamp,\n",
    "                    \"last_time\": timestamp\n",
    "                }\n",
    "                disappearance_counts[id] = 0  # Reset disappearance count\n",
    "            else:\n",
    "                # Update the last detection time\n",
    "                tracking_timestamps[id]['last_time'] = timestamp\n",
    "                disappearance_counts[id] = 0  # Reset disappearance count\n",
    "\n",
    "            # Update the frame buffer (store the most recent frame where the object was seen)\n",
    "            frame_buffer[id] = (int(x1), int(y1), int(x2), int(y2))\n",
    "\n",
    "            # Draw bounding box and label on the frame\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, c, (int(x1), int(y1) + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Process the objects that were detected in previous frames but not in the current frame\n",
    "    for id in list(tracking_timestamps.keys()):\n",
    "        if id not in detected_ids:\n",
    "            # If the object is not detected, increment the disappearance count\n",
    "            disappearance_counts[id] += 1\n",
    "\n",
    "            # If the object has been missing for fewer than debounce_limit frames, don't finalize yet\n",
    "            if disappearance_counts[id] <= debounce_limit:\n",
    "                # Use the last known bounding box from the frame buffer\n",
    "                x1, y1, x2, y2 = frame_buffer[id]\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)  # Yellow box for missing object\n",
    "                cv2.putText(frame, tracking_timestamps[id]['class'], (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            else:\n",
    "                # Once the debounce limit is exceeded, finalize the track and remove the object\n",
    "                tracking_data_json.append({\n",
    "                    \"name\": tracking_timestamps[id]['class'],\n",
    "                    \"trackId\": id,\n",
    "                    \"startTime\": f\"{tracking_timestamps[id]['start_time']:.2f}s\",\n",
    "                    \"endTime\": f\"{tracking_timestamps[id]['last_time']:.2f}s\"\n",
    "                })\n",
    "                # Remove the object from tracking\n",
    "                del tracking_timestamps[id]\n",
    "                del disappearance_counts[id]\n",
    "                del frame_buffer[id]\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Optionally, show the frame in real-time (commented out)\n",
    "    # cv2.imshow(\"frames\", frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "    #     break\n",
    "\n",
    "# Release video capture and writer resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the simplified JSON output to a file (automatically overwrites)\n",
    "with open('tracking_data_output.json', 'w') as f:\n",
    "    json.dump(tracking_data_json, f, indent=4)\n",
    "\n",
    "print(\"Tracking data has been saved to 'tracking_data_output.json'\")\n",
    "print(f\"Output video saved as '{output_video_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15080\\283500956.py:26: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap('tab20', num_objects)  # Use the 'tab20' colormap\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the JSON file\n",
    "with open('tracking_data_output.json', 'r') as f:\n",
    "    tracking_data = json.load(f)\n",
    "\n",
    "# Extract unique objects (names)\n",
    "unique_objects = list(set([item['name'] for item in tracking_data]))\n",
    "\n",
    "# Prepare data for plotting\n",
    "object_intervals = []\n",
    "object_names = []\n",
    "for obj in tracking_data:\n",
    "    start_time = float(obj['startTime'][:-1])  # Remove 's' and convert to float\n",
    "    end_time = float(obj['endTime'][:-1])      # Remove 's' and convert to float\n",
    "    object_intervals.append((start_time, end_time))\n",
    "    object_names.append(obj['name'])\n",
    "\n",
    "# Map object names to unique indices (for plotting purposes)\n",
    "name_to_idx = {name: idx for idx, name in enumerate(unique_objects)}\n",
    "\n",
    "# Set a unique color for each object\n",
    "num_objects = len(unique_objects)\n",
    "colors = plt.cm.get_cmap('tab20', num_objects)  # Use the 'tab20' colormap\n",
    "\n",
    "# Create a plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot each object's timeline as a horizontal bar with different colors\n",
    "for i, (start, end) in enumerate(object_intervals):\n",
    "    obj_name = object_names[i]\n",
    "    idx = name_to_idx[obj_name]\n",
    "    color = colors(idx)  # Get the color for this object\n",
    "    ax.broken_barh([(start, end - start)], (idx * 2 - 0.4, 0.8), facecolors=color)\n",
    "\n",
    "# Set y-axis labels to object names with more space between them\n",
    "ax.set_yticks([name_to_idx[name] * 2 for name in unique_objects])\n",
    "ax.set_yticklabels(unique_objects)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Time (seconds)')\n",
    "ax.set_ylabel('Objects')\n",
    "\n",
    "# Add gridlines for both axes\n",
    "ax.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Set x-axis limits and label every second\n",
    "max_time = max(end for start, end in object_intervals) + 10\n",
    "ax.set_xticks(np.arange(0, max_time + 1, 1))  # Label every second\n",
    "ax.set_xlim(0, max_time)\n",
    "\n",
    "# Increase spacing between objects\n",
    "ax.set_ylim(-1, num_objects * 2)\n",
    "\n",
    "# Title of the plot\n",
    "ax.set_title('Object Detection Timeline')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
