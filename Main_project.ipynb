{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Properties: 1920x1080, 20.121437752071976 FPS, 227 frames\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 89.9ms\n",
      "Speed: 2.4ms preprocess, 89.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 86.5ms\n",
      "Speed: 2.7ms preprocess, 86.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 91.9ms\n",
      "Speed: 0.0ms preprocess, 91.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 73.9ms\n",
      "Speed: 1.2ms preprocess, 73.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 71.0ms\n",
      "Speed: 2.4ms preprocess, 71.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 93.6ms\n",
      "Speed: 2.5ms preprocess, 93.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 90.3ms\n",
      "Speed: 1.3ms preprocess, 90.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 92.7ms\n",
      "Speed: 0.0ms preprocess, 92.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 87.0ms\n",
      "Speed: 2.1ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 83.2ms\n",
      "Speed: 0.0ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 108.9ms\n",
      "Speed: 0.0ms preprocess, 108.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 102.4ms\n",
      "Speed: 1.0ms preprocess, 102.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 84.3ms\n",
      "Speed: 2.8ms preprocess, 84.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 104.9ms\n",
      "Speed: 0.0ms preprocess, 104.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 86.6ms\n",
      "Speed: 1.6ms preprocess, 86.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 78.7ms\n",
      "Speed: 1.2ms preprocess, 78.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 92.4ms\n",
      "Speed: 0.0ms preprocess, 92.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 83.4ms\n",
      "Speed: 1.5ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 4.2ms preprocess, 68.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.8ms\n",
      "Speed: 4.5ms preprocess, 95.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.6ms\n",
      "Speed: 1.0ms preprocess, 82.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.4ms\n",
      "Speed: 2.0ms preprocess, 77.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.2ms\n",
      "Speed: 2.0ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.6ms\n",
      "Speed: 2.0ms preprocess, 84.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 93.3ms\n",
      "Speed: 2.0ms preprocess, 93.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 106.1ms\n",
      "Speed: 2.7ms preprocess, 106.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 79.8ms\n",
      "Speed: 0.0ms preprocess, 79.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 81.8ms\n",
      "Speed: 1.5ms preprocess, 81.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 81.4ms\n",
      "Speed: 2.0ms preprocess, 81.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 75.5ms\n",
      "Speed: 0.0ms preprocess, 75.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 71.5ms\n",
      "Speed: 1.5ms preprocess, 71.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 105.1ms\n",
      "Speed: 2.3ms preprocess, 105.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 77.3ms\n",
      "Speed: 2.1ms preprocess, 77.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 75.4ms\n",
      "Speed: 3.7ms preprocess, 75.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 82.6ms\n",
      "Speed: 0.0ms preprocess, 82.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.7ms\n",
      "Speed: 1.3ms preprocess, 100.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 80.6ms\n",
      "Speed: 0.0ms preprocess, 80.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 87.9ms\n",
      "Speed: 3.1ms preprocess, 87.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 101.8ms\n",
      "Speed: 2.0ms preprocess, 101.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 72.6ms\n",
      "Speed: 1.0ms preprocess, 72.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 112.1ms\n",
      "Speed: 2.6ms preprocess, 112.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 112.4ms\n",
      "Speed: 2.0ms preprocess, 112.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 109.1ms\n",
      "Speed: 0.0ms preprocess, 109.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 111.5ms\n",
      "Speed: 1.3ms preprocess, 111.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 114.1ms\n",
      "Speed: 2.0ms preprocess, 114.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 96.0ms\n",
      "Speed: 4.2ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 91.9ms\n",
      "Speed: 1.8ms preprocess, 91.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 89.4ms\n",
      "Speed: 1.9ms preprocess, 89.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 92.9ms\n",
      "Speed: 1.2ms preprocess, 92.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 96.3ms\n",
      "Speed: 2.2ms preprocess, 96.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 104.9ms\n",
      "Speed: 0.0ms preprocess, 104.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 81.2ms\n",
      "Speed: 1.0ms preprocess, 81.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 88.1ms\n",
      "Speed: 0.0ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 79.7ms\n",
      "Speed: 0.0ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 86.9ms\n",
      "Speed: 0.0ms preprocess, 86.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 104.3ms\n",
      "Speed: 5.6ms preprocess, 104.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 112.3ms\n",
      "Speed: 0.9ms preprocess, 112.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 107.8ms\n",
      "Speed: 1.5ms preprocess, 107.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 110.2ms\n",
      "Speed: 2.4ms preprocess, 110.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 113.6ms\n",
      "Speed: 4.2ms preprocess, 113.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.9ms\n",
      "Speed: 2.7ms preprocess, 111.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 88.0ms\n",
      "Speed: 1.6ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 73.4ms\n",
      "Speed: 2.5ms preprocess, 73.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 84.2ms\n",
      "Speed: 1.1ms preprocess, 84.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 112.6ms\n",
      "Speed: 1.5ms preprocess, 112.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 114.1ms\n",
      "Speed: 0.7ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 116.6ms\n",
      "Speed: 0.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 127.5ms\n",
      "Speed: 2.1ms preprocess, 127.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 113.7ms\n",
      "Speed: 2.1ms preprocess, 113.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 101.0ms\n",
      "Speed: 1.1ms preprocess, 101.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 103.4ms\n",
      "Speed: 1.0ms preprocess, 103.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 113.0ms\n",
      "Speed: 2.7ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 115.1ms\n",
      "Speed: 2.1ms preprocess, 115.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 114.7ms\n",
      "Speed: 1.4ms preprocess, 114.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 92.7ms\n",
      "Speed: 4.0ms preprocess, 92.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 108.6ms\n",
      "Speed: 3.7ms preprocess, 108.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 92.2ms\n",
      "Speed: 0.0ms preprocess, 92.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 105.3ms\n",
      "Speed: 0.0ms preprocess, 105.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 103.1ms\n",
      "Speed: 2.0ms preprocess, 103.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 112.4ms\n",
      "Speed: 1.8ms preprocess, 112.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 105.4ms\n",
      "Speed: 0.0ms preprocess, 105.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 110.2ms\n",
      "Speed: 2.0ms preprocess, 110.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 113.0ms\n",
      "Speed: 2.2ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 108.9ms\n",
      "Speed: 0.0ms preprocess, 108.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 77.1ms\n",
      "Speed: 2.4ms preprocess, 77.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 74.7ms\n",
      "Speed: 2.8ms preprocess, 74.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 89.4ms\n",
      "Speed: 1.0ms preprocess, 89.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 70.4ms\n",
      "Speed: 1.3ms preprocess, 70.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 102.5ms\n",
      "Speed: 1.2ms preprocess, 102.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 97.4ms\n",
      "Speed: 0.7ms preprocess, 97.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 109.8ms\n",
      "Speed: 2.0ms preprocess, 109.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 107.5ms\n",
      "Speed: 1.0ms preprocess, 107.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 117.5ms\n",
      "Speed: 2.5ms preprocess, 117.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 86.1ms\n",
      "Speed: 1.0ms preprocess, 86.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 98.0ms\n",
      "Speed: 0.0ms preprocess, 98.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 77.3ms\n",
      "Speed: 1.6ms preprocess, 77.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 88.1ms\n",
      "Speed: 0.0ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 107.2ms\n",
      "Speed: 1.3ms preprocess, 107.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 112.9ms\n",
      "Speed: 2.0ms preprocess, 112.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 110.9ms\n",
      "Speed: 2.4ms preprocess, 110.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 103.3ms\n",
      "Speed: 0.0ms preprocess, 103.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 115.6ms\n",
      "Speed: 1.5ms preprocess, 115.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 80.4ms\n",
      "Speed: 0.0ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 80.3ms\n",
      "Speed: 1.4ms preprocess, 80.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 96.0ms\n",
      "Speed: 1.7ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 82.3ms\n",
      "Speed: 1.5ms preprocess, 82.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 77.3ms\n",
      "Speed: 2.4ms preprocess, 77.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 77.8ms\n",
      "Speed: 0.0ms preprocess, 77.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 80.5ms\n",
      "Speed: 2.3ms preprocess, 80.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 91.9ms\n",
      "Speed: 4.0ms preprocess, 91.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 73.4ms\n",
      "Speed: 0.0ms preprocess, 73.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 81.7ms\n",
      "Speed: 3.0ms preprocess, 81.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 85.3ms\n",
      "Speed: 2.0ms preprocess, 85.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 80.6ms\n",
      "Speed: 4.0ms preprocess, 80.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 80.5ms\n",
      "Speed: 1.0ms preprocess, 80.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 91.7ms\n",
      "Speed: 4.4ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 85.2ms\n",
      "Speed: 2.0ms preprocess, 85.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 90.1ms\n",
      "Speed: 5.7ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 77.9ms\n",
      "Speed: 1.9ms preprocess, 77.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 97.8ms\n",
      "Speed: 0.0ms preprocess, 97.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 87.6ms\n",
      "Speed: 2.0ms preprocess, 87.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 81.6ms\n",
      "Speed: 4.0ms preprocess, 81.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 81.6ms\n",
      "Speed: 2.0ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 74.8ms\n",
      "Speed: 0.0ms preprocess, 74.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 76.6ms\n",
      "Speed: 0.0ms preprocess, 76.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 85.5ms\n",
      "Speed: 2.6ms preprocess, 85.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 71.9ms\n",
      "Speed: 2.0ms preprocess, 71.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 96.6ms\n",
      "Speed: 1.0ms preprocess, 96.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 94.0ms\n",
      "Speed: 2.0ms preprocess, 94.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 91.7ms\n",
      "Speed: 2.0ms preprocess, 91.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 79.3ms\n",
      "Speed: 1.9ms preprocess, 79.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 68.4ms\n",
      "Speed: 1.4ms preprocess, 68.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 78.7ms\n",
      "Speed: 1.9ms preprocess, 78.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 76.8ms\n",
      "Speed: 3.2ms preprocess, 76.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 95.5ms\n",
      "Speed: 3.8ms preprocess, 95.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 73.0ms\n",
      "Speed: 1.7ms preprocess, 73.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 80.0ms\n",
      "Speed: 0.0ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 76.7ms\n",
      "Speed: 3.0ms preprocess, 76.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 80.2ms\n",
      "Speed: 1.4ms preprocess, 80.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 82.6ms\n",
      "Speed: 1.0ms preprocess, 82.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 81.5ms\n",
      "Speed: 2.0ms preprocess, 81.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 94.4ms\n",
      "Speed: 1.5ms preprocess, 94.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 104.8ms\n",
      "Speed: 0.0ms preprocess, 104.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 82.2ms\n",
      "Speed: 1.5ms preprocess, 82.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 81.9ms\n",
      "Speed: 5.9ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 81.1ms\n",
      "Speed: 2.5ms preprocess, 81.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 100.6ms\n",
      "Speed: 0.0ms preprocess, 100.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 1 bed, 87.8ms\n",
      "Speed: 0.5ms preprocess, 87.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 96.4ms\n",
      "Speed: 1.0ms preprocess, 96.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 97.8ms\n",
      "Speed: 2.1ms preprocess, 97.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 108.3ms\n",
      "Speed: 4.0ms preprocess, 108.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 102.3ms\n",
      "Speed: 2.0ms preprocess, 102.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 82.6ms\n",
      "Speed: 0.0ms preprocess, 82.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 83.5ms\n",
      "Speed: 1.0ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 78.1ms\n",
      "Speed: 5.4ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 93.1ms\n",
      "Speed: 1.0ms preprocess, 93.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 77.8ms\n",
      "Speed: 5.7ms preprocess, 77.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 98.3ms\n",
      "Speed: 1.8ms preprocess, 98.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 96.7ms\n",
      "Speed: 4.5ms preprocess, 96.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 80.1ms\n",
      "Speed: 0.0ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 0.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.8ms\n",
      "Speed: 0.8ms preprocess, 100.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.7ms\n",
      "Speed: 2.0ms preprocess, 90.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 101.6ms\n",
      "Speed: 3.0ms preprocess, 101.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.7ms\n",
      "Speed: 0.0ms preprocess, 99.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 81.6ms\n",
      "Speed: 1.8ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.3ms\n",
      "Speed: 2.2ms preprocess, 81.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 84.4ms\n",
      "Speed: 1.5ms preprocess, 84.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 93.0ms\n",
      "Speed: 2.0ms preprocess, 93.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 90.1ms\n",
      "Speed: 0.0ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 87.3ms\n",
      "Speed: 0.0ms preprocess, 87.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 108.5ms\n",
      "Speed: 1.5ms preprocess, 108.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 111.3ms\n",
      "Speed: 3.2ms preprocess, 111.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 112.5ms\n",
      "Speed: 4.5ms preprocess, 112.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 110.8ms\n",
      "Speed: 3.9ms preprocess, 110.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 103.2ms\n",
      "Speed: 1.2ms preprocess, 103.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 93.2ms\n",
      "Speed: 2.3ms preprocess, 93.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 80.8ms\n",
      "Speed: 4.1ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 117.4ms\n",
      "Speed: 1.3ms preprocess, 117.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 96.0ms\n",
      "Speed: 1.1ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 76.2ms\n",
      "Speed: 4.5ms preprocess, 76.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 78.0ms\n",
      "Speed: 5.4ms preprocess, 78.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 backpack, 2 beds, 83.2ms\n",
      "Speed: 1.8ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 71.7ms\n",
      "Speed: 1.5ms preprocess, 71.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 77.3ms\n",
      "Speed: 1.0ms preprocess, 77.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 92.2ms\n",
      "Speed: 3.7ms preprocess, 92.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 78.5ms\n",
      "Speed: 2.0ms preprocess, 78.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 82.7ms\n",
      "Speed: 1.2ms preprocess, 82.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 80.1ms\n",
      "Speed: 1.0ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 92.0ms\n",
      "Speed: 1.6ms preprocess, 92.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 88.2ms\n",
      "Speed: 2.0ms preprocess, 88.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 94.3ms\n",
      "Speed: 1.8ms preprocess, 94.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 83.9ms\n",
      "Speed: 0.0ms preprocess, 83.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 80.7ms\n",
      "Speed: 0.0ms preprocess, 80.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 83.3ms\n",
      "Speed: 0.0ms preprocess, 83.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 94.6ms\n",
      "Speed: 4.7ms preprocess, 94.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 100.3ms\n",
      "Speed: 2.0ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 75.4ms\n",
      "Speed: 2.0ms preprocess, 75.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 90.3ms\n",
      "Speed: 0.0ms preprocess, 90.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 99.0ms\n",
      "Speed: 0.0ms preprocess, 99.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 80.1ms\n",
      "Speed: 1.8ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 86.5ms\n",
      "Speed: 2.4ms preprocess, 86.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 84.9ms\n",
      "Speed: 1.6ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 110.2ms\n",
      "Speed: 2.5ms preprocess, 110.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 114.7ms\n",
      "Speed: 0.0ms preprocess, 114.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 115.8ms\n",
      "Speed: 0.0ms preprocess, 115.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 115.7ms\n",
      "Speed: 0.0ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 126.2ms\n",
      "Speed: 2.3ms preprocess, 126.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 128.8ms\n",
      "Speed: 2.0ms preprocess, 128.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 2 beds, 105.1ms\n",
      "Speed: 1.2ms preprocess, 105.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 115.4ms\n",
      "Speed: 2.6ms preprocess, 115.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 121.1ms\n",
      "Speed: 1.5ms preprocess, 121.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 115.1ms\n",
      "Speed: 1.1ms preprocess, 115.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 104.7ms\n",
      "Speed: 2.0ms preprocess, 104.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 116.9ms\n",
      "Speed: 3.9ms preprocess, 116.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 113.7ms\n",
      "Speed: 0.0ms preprocess, 113.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 117.6ms\n",
      "Speed: 2.0ms preprocess, 117.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 bed, 115.7ms\n",
      "Speed: 1.9ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Output video saved to: C:\\Users\\irahu\\AppData\\Local\\Temp\\output_video.mp4\n",
      "Tracking data JSON saved to: C:\\Users\\irahu\\AppData\\Local\\Temp\\tracking_data_output.json\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Cell 1: Model Processing\n",
    "# ========================\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import tempfile\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data='dataset\\\\data.yaml', epochs=500, batch=256, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO('yolov10m.pt')  # Ensure the correct model is loaded\n",
    "class_list = model.names\n",
    "\n",
    "# Define the video processing function\n",
    "def process_video(input_path):\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Error opening video file\")\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Video Properties: {frame_width}x{frame_height}, {fps} FPS, {total_frames} frames\")\n",
    "\n",
    "    # Setup output video path and writer\n",
    "    output_video_path = os.path.join(tempfile.gettempdir(), \"output_video.mp4\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Initialize tracking data structures\n",
    "    tracking_timestamps = {}\n",
    "    disappearance_counts = {}\n",
    "    debounce_limit = 10\n",
    "    frame_buffer = {}\n",
    "    tracking_data_json = []\n",
    "\n",
    "    frame_number = 0\n",
    "\n",
    "    # Process video frame by frame\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_number += 1\n",
    "        timestamp = frame_number / fps\n",
    "        results = model.predict(frame)\n",
    "        detected_ids = []\n",
    "\n",
    "        # Process detected objects\n",
    "        if results and results[0].boxes is not None:\n",
    "            for box in results[0].boxes.data.cpu().numpy():\n",
    "                x1, y1, x2, y2, conf, cls = box\n",
    "                if conf > 0.5 and int(cls) < len(class_list):\n",
    "                    label = class_list[int(cls)]\n",
    "                    object_id = int(cls)\n",
    "                    detected_ids.append(object_id)\n",
    "\n",
    "                    # Update tracking information\n",
    "                    if object_id not in tracking_timestamps:\n",
    "                        tracking_timestamps[object_id] = {\n",
    "                            \"class\": label,\n",
    "                            \"trackId\": object_id,\n",
    "                            \"startTime\": timestamp,\n",
    "                            \"lastSeenTime\": timestamp,\n",
    "                            \"detectedFrames\": 1\n",
    "                        }\n",
    "                        disappearance_counts[object_id] = 0\n",
    "                    else:\n",
    "                        tracking_timestamps[object_id][\"lastSeenTime\"] = timestamp\n",
    "                        tracking_timestamps[object_id][\"detectedFrames\"] += 1\n",
    "                        disappearance_counts[object_id] = 0\n",
    "\n",
    "                    # Draw bounding boxes\n",
    "                    frame_buffer[object_id] = (int(x1), int(y1), int(x2), int(y2))\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Handle objects not detected in the current frame\n",
    "        for obj_id in list(tracking_timestamps.keys()):\n",
    "            if obj_id not in detected_ids:\n",
    "                disappearance_counts[obj_id] += 1\n",
    "                if disappearance_counts[obj_id] > debounce_limit:\n",
    "                    # Record tracking data when object disappears\n",
    "                    tracking_data_json.append({\n",
    "                        \"name\": tracking_timestamps[obj_id][\"class\"],\n",
    "                        \"trackId\": tracking_timestamps[obj_id][\"trackId\"],\n",
    "                        \"startTime\": f\"{tracking_timestamps[obj_id]['startTime']:.2f}s\",\n",
    "                        \"endTime\": f\"{tracking_timestamps[obj_id]['lastSeenTime']:.2f}s\",\n",
    "                        \"duration\": f\"{(tracking_timestamps[obj_id]['lastSeenTime'] - tracking_timestamps[obj_id]['startTime']):.2f}s\",\n",
    "                        \"totalFramesDetected\": tracking_timestamps[obj_id][\"detectedFrames\"]\n",
    "                    })\n",
    "                    # Remove the object from tracking once recorded\n",
    "                    del tracking_timestamps[obj_id]\n",
    "                    del disappearance_counts[obj_id]\n",
    "                    del frame_buffer[obj_id]\n",
    "\n",
    "        # Write processed frame to output video\n",
    "        out.write(frame)\n",
    "\n",
    "    # Finalize JSON tracking data for any remaining objects\n",
    "    for obj_id in list(tracking_timestamps.keys()):\n",
    "        tracking_data_json.append({\n",
    "            \"name\": tracking_timestamps[obj_id][\"class\"],\n",
    "            \"trackId\": tracking_timestamps[obj_id][\"trackId\"],\n",
    "            \"startTime\": f\"{tracking_timestamps[obj_id]['startTime']:.2f}s\",\n",
    "            \"endTime\": f\"{tracking_timestamps[obj_id]['lastSeenTime']:.2f}s\",\n",
    "            \"duration\": f\"{(tracking_timestamps[obj_id]['lastSeenTime'] - tracking_timestamps[obj_id]['startTime']):.2f}s\",\n",
    "            \"totalFramesDetected\": tracking_timestamps[obj_id][\"detectedFrames\"]\n",
    "        })\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Save tracking data to JSON file\n",
    "    json_path = os.path.join(tempfile.gettempdir(), \"tracking_data_output.json\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(tracking_data_json, f, indent=4)\n",
    "\n",
    "    return output_video_path, json_path\n",
    "\n",
    "# Provide the input video path (manually specify the path)\n",
    "input_video_path = \"test2.mp4\"  # Change this path\n",
    "output_video_path, json_file_path = process_video(input_video_path)\n",
    "\n",
    "print(f\"Output video saved to: {output_video_path}\")\n",
    "print(f\"Tracking data JSON saved to: {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irahu\\AppData\\Local\\Temp\\ipykernel_38248\\2337274018.py:30: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab20\", len(unique_objects))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# Cell 2: Graph Generation\n",
    "# ========================\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load tracking data from JSON file\n",
    "json_path = os.path.join(tempfile.gettempdir(), \"tracking_data_output.json\")\n",
    "with open(json_path, \"r\") as f:\n",
    "    tracking_data = json.load(f)\n",
    "\n",
    "# print(f\"Tracking Data: {tracking_data}\")\n",
    "\n",
    "# Generate a timeline graph of detected objects\n",
    "unique_objects = list(set([item[\"name\"] for item in tracking_data]))\n",
    "object_intervals = []\n",
    "object_names = []\n",
    "\n",
    "# Extract intervals and object names for plotting\n",
    "for obj in tracking_data:\n",
    "    start_time = float(obj[\"startTime\"][:-1])\n",
    "    end_time = float(obj[\"endTime\"][:-1])\n",
    "    object_intervals.append((start_time, end_time))\n",
    "    object_names.append(obj[\"name\"])\n",
    "\n",
    "# Map object names to indices for unique identification\n",
    "name_to_idx = {name: idx for idx, name in enumerate(unique_objects)}\n",
    "colors = plt.cm.get_cmap(\"tab20\", len(unique_objects))\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "for i, (start, end) in enumerate(object_intervals):\n",
    "    idx = name_to_idx[object_names[i]]\n",
    "    ax.broken_barh([(start, end - start)], (idx * 2 - 0.4, 0.8), facecolors=colors(idx))\n",
    "\n",
    "# Customize plot appearance\n",
    "ax.set_yticks([name_to_idx[name] * 2 for name in unique_objects])\n",
    "ax.set_yticklabels(unique_objects)\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Detected Objects\")\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "ax.set_title(\"Object Detection Timeline\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
